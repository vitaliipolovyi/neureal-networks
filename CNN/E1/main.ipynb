{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "from inout import load_mnist\n",
    "from utils import preprocess\n",
    "from network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "dataset_name = 'mnist'\n",
    "num_epochs = 1\n",
    "learning_rate = 0.01\n",
    "validate = 1\n",
    "regularization = 0\n",
    "verbose = 1\n",
    "plot_weights = 1\n",
    "plot_correct = 1\n",
    "plot_missclassified = 1\n",
    "plot_feature_maps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading mnist dataset ---\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print('\\n--- Loading ' + dataset_name + ' dataset ---')                 # load dataset\n",
    "dataset = load_mnist() # if dataset_name is 'mnist' else load_cifar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing the dataset ---\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print('\\n--- Processing the dataset ---')                               # pre process dataset\n",
    "dataset = preprocess(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Building the model ---\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print('\\n--- Building the model ---')                                   # build model\n",
    "model = Network()\n",
    "model.build_model(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training the model ---\n",
      "\n",
      "--- Epoch 1 ---\n",
      "[Step 00100]: Loss 2.212 | Accuracy: 18.000 | Time: 55.16 seconds | Validation Loss 2.146 | Validation Accuracy: 22.660\n",
      "[Step 00200]: Loss 2.039 | Accuracy: 26.500 | Time: 52.34 seconds | Validation Loss 1.397 | Validation Accuracy: 56.120\n",
      "[Step 00300]: Loss 1.766 | Accuracy: 38.333 | Time: 60.99 seconds | Validation Loss 1.012 | Validation Accuracy: 68.600\n",
      "[Step 00400]: Loss 1.584 | Accuracy: 45.000 | Time: 54.36 seconds | Validation Loss 0.871 | Validation Accuracy: 71.620\n",
      "[Step 00500]: Loss 1.421 | Accuracy: 50.400 | Time: 64.88 seconds | Validation Loss 0.718 | Validation Accuracy: 77.920\n",
      "[Step 00600]: Loss 1.311 | Accuracy: 54.667 | Time: 54.78 seconds | Validation Loss 0.689 | Validation Accuracy: 77.140\n",
      "[Step 00700]: Loss 1.207 | Accuracy: 58.571 | Time: 56.72 seconds | Validation Loss 0.637 | Validation Accuracy: 81.360\n",
      "[Step 00800]: Loss 1.169 | Accuracy: 61.000 | Time: 53.87 seconds | Validation Loss 0.693 | Validation Accuracy: 79.140\n",
      "[Step 00900]: Loss 1.100 | Accuracy: 63.333 | Time: 57.17 seconds | Validation Loss 0.649 | Validation Accuracy: 80.280\n",
      "[Step 01000]: Loss 1.064 | Accuracy: 65.400 | Time: 62.14 seconds | Validation Loss 0.615 | Validation Accuracy: 81.320\n",
      "[Step 01100]: Loss 1.031 | Accuracy: 67.182 | Time: 75.80 seconds | Validation Loss 0.621 | Validation Accuracy: 82.840\n",
      "[Step 01200]: Loss 1.000 | Accuracy: 68.333 | Time: 59.37 seconds | Validation Loss 0.715 | Validation Accuracy: 77.200\n",
      "[Step 01300]: Loss 0.963 | Accuracy: 69.692 | Time: 46.00 seconds | Validation Loss 0.575 | Validation Accuracy: 82.980\n",
      "[Step 01400]: Loss 0.942 | Accuracy: 69.929 | Time: 45.81 seconds | Validation Loss 0.601 | Validation Accuracy: 82.000\n",
      "[Step 01500]: Loss 0.912 | Accuracy: 70.867 | Time: 83.19 seconds | Validation Loss 0.615 | Validation Accuracy: 82.640\n",
      "[Step 01600]: Loss 0.883 | Accuracy: 71.875 | Time: 63.09 seconds | Validation Loss 0.650 | Validation Accuracy: 82.600\n",
      "[Step 01700]: Loss 0.867 | Accuracy: 72.765 | Time: 60.64 seconds | Validation Loss 0.599 | Validation Accuracy: 82.960\n",
      "[Step 01800]: Loss 0.849 | Accuracy: 73.222 | Time: 65.60 seconds | Validation Loss 0.535 | Validation Accuracy: 84.540\n",
      "[Step 01900]: Loss 0.827 | Accuracy: 73.842 | Time: 50.02 seconds | Validation Loss 0.655 | Validation Accuracy: 82.440\n",
      "[Step 02000]: Loss 0.801 | Accuracy: 74.650 | Time: 58.00 seconds | Validation Loss 0.574 | Validation Accuracy: 84.560\n",
      "[Step 02100]: Loss 0.787 | Accuracy: 75.143 | Time: 69.12 seconds | Validation Loss 0.509 | Validation Accuracy: 85.460\n",
      "[Step 02200]: Loss 0.784 | Accuracy: 75.182 | Time: 53.57 seconds | Validation Loss 0.529 | Validation Accuracy: 84.180\n",
      "[Step 02300]: Loss 0.776 | Accuracy: 75.478 | Time: 52.13 seconds | Validation Loss 0.509 | Validation Accuracy: 85.460\n",
      "[Step 02400]: Loss 0.761 | Accuracy: 75.958 | Time: 48.88 seconds | Validation Loss 0.505 | Validation Accuracy: 86.200\n",
      "[Step 02500]: Loss 0.755 | Accuracy: 76.120 | Time: 54.66 seconds | Validation Loss 0.586 | Validation Accuracy: 82.380\n",
      "[Step 02600]: Loss 0.749 | Accuracy: 76.308 | Time: 45.80 seconds | Validation Loss 0.509 | Validation Accuracy: 84.940\n",
      "[Step 02700]: Loss 0.733 | Accuracy: 76.815 | Time: 49.14 seconds | Validation Loss 0.569 | Validation Accuracy: 83.540\n",
      "[Step 02800]: Loss 0.727 | Accuracy: 77.036 | Time: 49.09 seconds | Validation Loss 0.548 | Validation Accuracy: 83.060\n",
      "[Step 02900]: Loss 0.720 | Accuracy: 77.276 | Time: 46.00 seconds | Validation Loss 0.528 | Validation Accuracy: 84.900\n",
      "[Step 03000]: Loss 0.709 | Accuracy: 77.767 | Time: 46.63 seconds | Validation Loss 0.611 | Validation Accuracy: 81.560\n",
      "[Step 03100]: Loss 0.709 | Accuracy: 77.839 | Time: 46.01 seconds | Validation Loss 0.517 | Validation Accuracy: 84.620\n",
      "[Step 03200]: Loss 0.700 | Accuracy: 78.250 | Time: 46.36 seconds | Validation Loss 0.457 | Validation Accuracy: 87.560\n",
      "[Step 03300]: Loss 0.690 | Accuracy: 78.667 | Time: 45.65 seconds | Validation Loss 0.474 | Validation Accuracy: 86.760\n",
      "[Step 03400]: Loss 0.687 | Accuracy: 78.794 | Time: 45.71 seconds | Validation Loss 0.454 | Validation Accuracy: 86.900\n",
      "[Step 03500]: Loss 0.679 | Accuracy: 79.000 | Time: 49.23 seconds | Validation Loss 0.561 | Validation Accuracy: 84.960\n",
      "[Step 03600]: Loss 0.675 | Accuracy: 79.111 | Time: 45.94 seconds | Validation Loss 0.634 | Validation Accuracy: 81.500\n",
      "[Step 03700]: Loss 0.667 | Accuracy: 79.432 | Time: 49.48 seconds | Validation Loss 0.600 | Validation Accuracy: 83.880\n",
      "[Step 03800]: Loss 0.664 | Accuracy: 79.447 | Time: 52.73 seconds | Validation Loss 0.540 | Validation Accuracy: 84.780\n",
      "[Step 03900]: Loss 0.661 | Accuracy: 79.513 | Time: 52.36 seconds | Validation Loss 0.477 | Validation Accuracy: 86.040\n",
      "[Step 04000]: Loss 0.656 | Accuracy: 79.675 | Time: 52.23 seconds | Validation Loss 0.486 | Validation Accuracy: 85.940\n",
      "[Step 04100]: Loss 0.650 | Accuracy: 79.951 | Time: 49.60 seconds | Validation Loss 0.470 | Validation Accuracy: 85.620\n",
      "[Step 04200]: Loss 0.648 | Accuracy: 79.976 | Time: 52.10 seconds | Validation Loss 0.485 | Validation Accuracy: 86.480\n",
      "[Step 04300]: Loss 0.646 | Accuracy: 80.093 | Time: 49.11 seconds | Validation Loss 0.460 | Validation Accuracy: 86.660\n",
      "[Step 04400]: Loss 0.643 | Accuracy: 80.182 | Time: 46.58 seconds | Validation Loss 0.484 | Validation Accuracy: 86.460\n",
      "[Step 04500]: Loss 0.636 | Accuracy: 80.333 | Time: 47.06 seconds | Validation Loss 0.520 | Validation Accuracy: 85.560\n",
      "[Step 04600]: Loss 0.636 | Accuracy: 80.391 | Time: 48.27 seconds | Validation Loss 0.434 | Validation Accuracy: 87.640\n",
      "[Step 04700]: Loss 0.634 | Accuracy: 80.489 | Time: 47.43 seconds | Validation Loss 0.443 | Validation Accuracy: 86.620\n",
      "[Step 04800]: Loss 0.634 | Accuracy: 80.521 | Time: 49.50 seconds | Validation Loss 0.433 | Validation Accuracy: 87.160\n",
      "[Step 04900]: Loss 0.633 | Accuracy: 80.551 | Time: 46.42 seconds | Validation Loss 0.470 | Validation Accuracy: 86.700\n",
      "[Step 05000]: Loss 0.629 | Accuracy: 80.580 | Time: 46.41 seconds | Validation Loss 0.471 | Validation Accuracy: 86.880\n",
      "[Step 05100]: Loss 0.631 | Accuracy: 80.627 | Time: 52.32 seconds | Validation Loss 0.489 | Validation Accuracy: 85.540\n",
      "[Step 05200]: Loss 0.628 | Accuracy: 80.769 | Time: 46.22 seconds | Validation Loss 0.440 | Validation Accuracy: 87.740\n",
      "[Step 05300]: Loss 0.624 | Accuracy: 80.868 | Time: 45.56 seconds | Validation Loss 0.495 | Validation Accuracy: 85.940\n",
      "[Step 05400]: Loss 0.621 | Accuracy: 80.944 | Time: 60.44 seconds | Validation Loss 0.483 | Validation Accuracy: 86.020\n",
      "[Step 05500]: Loss 0.618 | Accuracy: 81.018 | Time: 53.30 seconds | Validation Loss 0.496 | Validation Accuracy: 85.880\n",
      "[Step 05600]: Loss 0.616 | Accuracy: 81.036 | Time: 61.92 seconds | Validation Loss 0.435 | Validation Accuracy: 87.640\n",
      "[Step 05700]: Loss 0.614 | Accuracy: 81.088 | Time: 55.38 seconds | Validation Loss 0.498 | Validation Accuracy: 85.100\n",
      "[Step 05800]: Loss 0.614 | Accuracy: 81.172 | Time: 56.76 seconds | Validation Loss 0.450 | Validation Accuracy: 87.140\n",
      "[Step 05900]: Loss 0.611 | Accuracy: 81.254 | Time: 62.95 seconds | Validation Loss 0.460 | Validation Accuracy: 85.760\n",
      "[Step 06000]: Loss 0.613 | Accuracy: 81.317 | Time: 46.29 seconds | Validation Loss 0.429 | Validation Accuracy: 87.540\n",
      "[Step 06100]: Loss 0.606 | Accuracy: 81.525 | Time: 63.45 seconds | Validation Loss 0.444 | Validation Accuracy: 87.380\n",
      "[Step 06200]: Loss 0.607 | Accuracy: 81.468 | Time: 68.07 seconds | Validation Loss 0.437 | Validation Accuracy: 86.920\n",
      "[Step 06300]: Loss 0.604 | Accuracy: 81.587 | Time: 57.59 seconds | Validation Loss 0.466 | Validation Accuracy: 87.320\n",
      "[Step 06400]: Loss 0.600 | Accuracy: 81.672 | Time: 64.00 seconds | Validation Loss 0.479 | Validation Accuracy: 86.660\n",
      "[Step 06500]: Loss 0.598 | Accuracy: 81.754 | Time: 74.45 seconds | Validation Loss 0.460 | Validation Accuracy: 86.720\n",
      "[Step 06600]: Loss 0.595 | Accuracy: 81.864 | Time: 56.77 seconds | Validation Loss 0.484 | Validation Accuracy: 86.620\n",
      "[Step 06700]: Loss 0.592 | Accuracy: 81.970 | Time: 61.34 seconds | Validation Loss 0.526 | Validation Accuracy: 86.460\n",
      "[Step 06800]: Loss 0.593 | Accuracy: 81.956 | Time: 70.85 seconds | Validation Loss 0.494 | Validation Accuracy: 85.700\n",
      "[Step 06900]: Loss 0.592 | Accuracy: 82.014 | Time: 52.89 seconds | Validation Loss 0.490 | Validation Accuracy: 85.920\n",
      "[Step 07000]: Loss 0.590 | Accuracy: 82.100 | Time: 46.05 seconds | Validation Loss 0.462 | Validation Accuracy: 86.100\n",
      "[Step 07100]: Loss 0.590 | Accuracy: 82.183 | Time: 75.38 seconds | Validation Loss 0.486 | Validation Accuracy: 85.620\n",
      "[Step 07200]: Loss 0.586 | Accuracy: 82.278 | Time: 59.97 seconds | Validation Loss 0.460 | Validation Accuracy: 87.640\n",
      "[Step 07300]: Loss 0.587 | Accuracy: 82.288 | Time: 74.82 seconds | Validation Loss 0.493 | Validation Accuracy: 85.660\n",
      "[Step 07400]: Loss 0.587 | Accuracy: 82.324 | Time: 60.98 seconds | Validation Loss 0.544 | Validation Accuracy: 85.580\n",
      "[Step 07500]: Loss 0.588 | Accuracy: 82.320 | Time: 64.59 seconds | Validation Loss 0.408 | Validation Accuracy: 88.300\n",
      "[Step 07600]: Loss 0.585 | Accuracy: 82.395 | Time: 73.93 seconds | Validation Loss 0.500 | Validation Accuracy: 86.900\n",
      "[Step 07700]: Loss 0.582 | Accuracy: 82.455 | Time: 64.62 seconds | Validation Loss 0.436 | Validation Accuracy: 87.480\n",
      "[Step 07800]: Loss 0.581 | Accuracy: 82.487 | Time: 65.49 seconds | Validation Loss 0.512 | Validation Accuracy: 86.240\n",
      "[Step 07900]: Loss 0.579 | Accuracy: 82.582 | Time: 69.97 seconds | Validation Loss 0.458 | Validation Accuracy: 86.720\n",
      "[Step 08000]: Loss 0.576 | Accuracy: 82.688 | Time: 53.13 seconds | Validation Loss 0.438 | Validation Accuracy: 87.240\n",
      "[Step 08100]: Loss 0.577 | Accuracy: 82.704 | Time: 60.24 seconds | Validation Loss 0.581 | Validation Accuracy: 83.160\n",
      "[Step 08200]: Loss 0.577 | Accuracy: 82.756 | Time: 48.66 seconds | Validation Loss 0.497 | Validation Accuracy: 85.640\n",
      "[Step 08300]: Loss 0.574 | Accuracy: 82.819 | Time: 68.52 seconds | Validation Loss 0.472 | Validation Accuracy: 86.340\n",
      "[Step 08400]: Loss 0.572 | Accuracy: 82.893 | Time: 67.19 seconds | Validation Loss 0.534 | Validation Accuracy: 84.640\n",
      "[Step 08500]: Loss 0.570 | Accuracy: 82.965 | Time: 74.07 seconds | Validation Loss 0.444 | Validation Accuracy: 87.820\n",
      "[Step 08600]: Loss 0.567 | Accuracy: 83.047 | Time: 75.09 seconds | Validation Loss 0.449 | Validation Accuracy: 87.660\n",
      "[Step 08700]: Loss 0.564 | Accuracy: 83.126 | Time: 71.29 seconds | Validation Loss 0.533 | Validation Accuracy: 85.960\n",
      "[Step 08800]: Loss 0.562 | Accuracy: 83.205 | Time: 67.29 seconds | Validation Loss 0.486 | Validation Accuracy: 87.300\n",
      "[Step 08900]: Loss 0.558 | Accuracy: 83.303 | Time: 75.13 seconds | Validation Loss 0.532 | Validation Accuracy: 86.260\n",
      "[Step 09000]: Loss 0.557 | Accuracy: 83.322 | Time: 74.19 seconds | Validation Loss 0.453 | Validation Accuracy: 86.960\n",
      "[Step 09100]: Loss 0.558 | Accuracy: 83.330 | Time: 85.75 seconds | Validation Loss 0.459 | Validation Accuracy: 86.980\n",
      "[Step 09200]: Loss 0.556 | Accuracy: 83.380 | Time: 74.92 seconds | Validation Loss 0.462 | Validation Accuracy: 87.500\n",
      "[Step 09300]: Loss 0.553 | Accuracy: 83.452 | Time: 79.14 seconds | Validation Loss 0.486 | Validation Accuracy: 86.160\n",
      "[Step 09400]: Loss 0.553 | Accuracy: 83.468 | Time: 82.41 seconds | Validation Loss 0.457 | Validation Accuracy: 86.420\n",
      "[Step 09500]: Loss 0.551 | Accuracy: 83.526 | Time: 75.58 seconds | Validation Loss 0.448 | Validation Accuracy: 87.200\n",
      "[Step 09600]: Loss 0.553 | Accuracy: 83.469 | Time: 78.26 seconds | Validation Loss 0.454 | Validation Accuracy: 87.640\n",
      "[Step 09700]: Loss 0.553 | Accuracy: 83.485 | Time: 69.81 seconds | Validation Loss 0.411 | Validation Accuracy: 88.520\n",
      "[Step 09800]: Loss 0.552 | Accuracy: 83.469 | Time: 91.69 seconds | Validation Loss 0.444 | Validation Accuracy: 88.100\n",
      "[Step 09900]: Loss 0.552 | Accuracy: 83.505 | Time: 58.70 seconds | Validation Loss 0.479 | Validation Accuracy: 85.540\n",
      "[Step 10000]: Loss 0.550 | Accuracy: 83.560 | Time: 76.63 seconds | Validation Loss 0.529 | Validation Accuracy: 84.320\n",
      "[Step 10100]: Loss 0.550 | Accuracy: 83.525 | Time: 62.45 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 10200]: Loss 0.551 | Accuracy: 83.510 | Time: 65.46 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 10300]: Loss 0.551 | Accuracy: 83.476 | Time: 71.18 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 10400]: Loss 0.551 | Accuracy: 83.452 | Time: 66.60 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 10500]: Loss 0.553 | Accuracy: 83.410 | Time: 71.84 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 10600]: Loss 0.553 | Accuracy: 83.396 | Time: 68.24 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 10700]: Loss 0.552 | Accuracy: 83.430 | Time: 61.81 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 10800]: Loss 0.553 | Accuracy: 83.398 | Time: 69.03 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 10900]: Loss 0.553 | Accuracy: 83.385 | Time: 68.26 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 11000]: Loss 0.553 | Accuracy: 83.364 | Time: 76.44 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 11100]: Loss 0.553 | Accuracy: 83.306 | Time: 68.71 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 11200]: Loss 0.553 | Accuracy: 83.357 | Time: 64.65 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 11300]: Loss 0.551 | Accuracy: 83.389 | Time: 70.71 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 11400]: Loss 0.552 | Accuracy: 83.360 | Time: 69.69 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 11500]: Loss 0.553 | Accuracy: 83.339 | Time: 65.38 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 11600]: Loss 0.552 | Accuracy: 83.353 | Time: 66.63 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 11700]: Loss 0.551 | Accuracy: 83.402 | Time: 61.36 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 11800]: Loss 0.552 | Accuracy: 83.381 | Time: 54.00 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 11900]: Loss 0.551 | Accuracy: 83.412 | Time: 58.59 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n",
      "[Step 12000]: Loss 0.552 | Accuracy: 83.350 | Time: 54.82 seconds | Validation Loss 0.592 | Validation Accuracy: 81.780\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Training the model ---\u001b[39m\u001b[38;5;124m'\u001b[39m)                                   \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregularization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Work/NeuralNetworks/Programmes/CNN/E1/network.py:61\u001b[0m, in \u001b[0;36mNetwork.train\u001b[0;34m(self, dataset, num_epochs, learning_rate, validate, regularization, plot_weights, verbose)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate:\n\u001b[1;32m     60\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_images\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 61\u001b[0m     val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation_images\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation_labels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregularization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_correct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_missclassified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_feature_maps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(val_loss)\n\u001b[1;32m     71\u001b[0m     history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(val_accuracy)\n",
      "File \u001b[0;32m~/Documents/Work/NeuralNetworks/Programmes/CNN/E1/network.py:117\u001b[0m, in \u001b[0;36mNetwork.evaluate\u001b[0;34m(self, X, y, regularization, plot_correct, plot_missclassified, plot_feature_maps, verbose)\u001b[0m\n\u001b[1;32m    115\u001b[0m loss, num_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)):\n\u001b[0;32m--> 117\u001b[0m     tmp_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_feature_maps\u001b[49m\u001b[43m)\u001b[49m              \u001b[38;5;66;03m# forward propagation\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# compute cross-entropy update loss\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m regularized_cross_entropy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers, regularization, tmp_output[y[i]])\n",
      "File \u001b[0;32m~/Documents/Work/NeuralNetworks/Programmes/CNN/E1/network.py:37\u001b[0m, in \u001b[0;36mNetwork.forward\u001b[0;34m(self, image, plot_feature_maps)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28mprint\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;66;03m#image = (image * 255)[0, :, :]\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;66;03m#plot_sample(image, None, None)\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "File \u001b[0;32m~/Documents/Work/NeuralNetworks/Programmes/CNN/E1/layers/convolutional.py:32\u001b[0m, in \u001b[0;36mConvolutional.forward\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m tmp_x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m input_dimension:\n\u001b[1;32m     31\u001b[0m     patch \u001b[38;5;241m=\u001b[39m image[:, tmp_y:tmp_y \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, tmp_x:tmp_x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize]\n\u001b[0;32m---> 32\u001b[0m     out[f, out_y, out_x] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     tmp_x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride\n\u001b[1;32m     34\u001b[0m     out_x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print('\\n--- Training the model ---')                                   # train model\n",
    "model.train(\n",
    "    dataset,\n",
    "    num_epochs,\n",
    "    learning_rate,\n",
    "    validate,\n",
    "    regularization,\n",
    "    plot_weights,\n",
    "    verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "from utils import regularized_cross_entropy, plot_learning_curve, plot_accuracy_curve, plot_histogram, plot_sample, lr_update\n",
    "import numpy as np\n",
    "\n",
    "def forward(image, plot_feature_maps):                # forward propagate\n",
    "    for layer in model.layers:\n",
    "        if plot_feature_maps:\n",
    "            plot_sample((image * 255)[0, :, :], None, None)\n",
    "        image = layer.forward(image)\n",
    "\n",
    "    return image\n",
    "  \n",
    "def evaluate(X, y, regularization, plot_correct, plot_missclassified, plot_feature_maps, verbose):\n",
    "    loss, num_correct = 0, 0\n",
    "    for i in range(len(X)):\n",
    "        tmp_output = forward(X[i], plot_feature_maps)              # forward propagation\n",
    "\n",
    "        # compute cross-entropy update loss\n",
    "        loss += regularized_cross_entropy(model.layers, regularization, tmp_output[y[i]])\n",
    "\n",
    "        prediction = np.argmax(tmp_output)                              # update accuracy\n",
    "        if prediction == y[i]:\n",
    "            num_correct += 1\n",
    "            if plot_correct:                                            # plot correctly classified digit\n",
    "                image = (X[i] * 255)[0, :, :]\n",
    "                plot_sample(image, y[i], prediction)\n",
    "                plot_correct = 1\n",
    "        else:\n",
    "            if plot_missclassified:                                     # plot missclassified digit\n",
    "                image = (X[i] * 255)[0, :, :]\n",
    "                plot_sample(image, y[i], prediction)\n",
    "                plot_missclassified = 1\n",
    "\n",
    "    test_size = len(X)\n",
    "    accuracy = (num_correct / test_size) * 100\n",
    "    loss = loss / test_size\n",
    "    if verbose:\n",
    "        print('Test Loss: %02.3f' % loss)\n",
    "        print('Test Accuracy: %02.3f' % accuracy)\n",
    "    return loss, accuracy\n",
    "\n",
    "evaluate(\n",
    "    dataset['test_images'],\n",
    "    dataset['test_labels'],\n",
    "    regularization,\n",
    "    plot_correct,\n",
    "    plot_missclassified,\n",
    "    plot_feature_maps,\n",
    "    verbose   \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
